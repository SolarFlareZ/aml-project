# @package _global_

defaults:
  - _self_

experiment_name: fl_task_arithmetic
seed: 42

# Data Configuration
data:
  data_dir: ./data
  batch_size: 32         
  num_workers: 0
  val_split: 0.1
  fl_clients: 100        # Standard for 100-class problems
  fl_rounds: 500         # Matches colleague's baseline length
  client_frac: 0.1       # 10% participation (10 clients per round)
  local_epochs: 3        # RECOMMENDED: Increased to build a stronger Task Vector
  iid: true
  non_iid_classes: 10
  image_size: 224

# Model Configuration
model:
  num_classes: 100
  freeze_backbone: false # REQUIRED for TaLoS Sparse Backbone tuning
  image_size: 224

# Trainer Configuration
trainer:
  accelerator: gpu       
  devices: 1
  precision: 16-mixed    # Faster training and less VRAM on RTX 4050
  val_check_interval: 10 # Check every 10 rounds to save time

# Optimizer Configuration
optimizer:
  lr: 1e-3
  momentum: 0.9
  weight_decay: 5e-4

# Task Arithmetic & Pruning Configuration
task_arithmetic:
  alpha: 0.4
pruning:
  sparsity: 0.5          # Matches your 152-layer Fisher Mask
  num_calibration_rounds: 3  # Number of calibration rounds for mask generation

# Logging
logging:
  log_dir: ./results/logs