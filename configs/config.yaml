# @package _global_

defaults:
  - _self_

experiment_name: fl_task_arithmetic
seed: 42

# Data Configuration
data:
  data_dir: ./data
  batch_size: 64         # Reduced for laptop CPU stability
  num_workers: 0
  val_split: 0.1
  fl_clients: 5          # Number of clients
  fl_rounds: 5           # Number of rounds
  client_frac: 0.4       # Fraction selected per round (0.4 * 5 = 2 clients)
  local_epochs: 1
  iid: true
  non_iid_classes: 10
  image_size: 224

# Model Configuration
model:
  num_classes: 100
  freeze_backbone: true
  image_size: 224

# Trainer Configuration
trainer:
  accelerator: cpu       # Set to 'cpu' since you are on a laptop
  devices: 1
  precision: 32          # Use 32 for CPU
  val_check_interval: 1  # Matches your script's cfg.trainer.val_check_interval

# Optimizer Configuration
optimizer:
  lr: 0.01
  momentum: 0.9
  weight_decay: 5e-4

# Task Arithmetic & Pruning Configuration
task_arithmetic:
  alpha: 0.4
pruning:
  sparsity: 0.5

# Logging
logging:
  log_dir: ./results/logs