{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2a210008",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a210008",
        "outputId": "99f80df4-8dc4-47d2-9a79-c9a0f0da6478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:19: SyntaxWarning: invalid escape sequence '\\c'\n",
            "<>:19: SyntaxWarning: invalid escape sequence '\\c'\n",
            "/tmp/ipython-input-360728156.py:19: SyntaxWarning: invalid escape sequence '\\c'\n",
            "  print(f\"\\curr dir: {os.getcwd()}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cloning repo...\n",
            "Cloning into 'aml-project'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Counting objects: 100% (207/207), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 207 (delta 83), reused 177 (delta 63), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (207/207), 2.72 MiB | 16.37 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n",
            "/content/aml-project\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\\curr dir: /content/aml-project\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "REPO = \"SolarFlareZ/aml-project\"\n",
        "BRANCH = \"main\"\n",
        "PROJECT_DIR = \"/content/aml-project\"\n",
        "\n",
        "if os.path.exists(PROJECT_DIR):\n",
        "    print(\"repo exists, pulling last commit\")\n",
        "    %cd {PROJECT_DIR}\n",
        "    !git checkout {BRANCH}\n",
        "    !git pull origin {BRANCH}\n",
        "else:\n",
        "    print(\"cloning repo...\")\n",
        "    !git clone -b {BRANCH} https://github.com/{REPO}.git\n",
        "    %cd {PROJECT_DIR}\n",
        "\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "print(f\"\\curr dir: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "54a3c5a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54a3c5a1",
        "outputId": "e5cca160-114a-4ec5-da04-f90b76f74f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config:\n",
            "experiment_name: quick_test\n",
            "seed: 42\n",
            "resume_from: null\n",
            "data:\n",
            "  data_dir: ./data\n",
            "  batch_size: 128\n",
            "  num_workers: 0\n",
            "  val_split: 0.1\n",
            "  fl_clients: 100\n",
            "  fl_rounds: 1000\n",
            "  client_frac: 0.1\n",
            "  local_epochs: 4\n",
            "  iid: true\n",
            "  non_iid_classes: 10\n",
            "model:\n",
            "  num_classes: 100\n",
            "  freeze_backbone: true\n",
            "  image_size: 224\n",
            "trainer:\n",
            "  max_epochs: 5\n",
            "  accelerator: auto\n",
            "  devices: 1\n",
            "  precision: 16-mixed\n",
            "  gradient_clip_val: 1.0\n",
            "  log_every_n_steps: 50\n",
            "  check_val_every_n_epoch: 1\n",
            "  accumulate_grad_batches: 1\n",
            "optimizer:\n",
            "  lr: 0.01\n",
            "  momentum: 0.9\n",
            "  weight_decay: 0.0005\n",
            "scheduler:\n",
            "  name: cosine\n",
            "logging:\n",
            "  log_dir: ./results/logs\n",
            "callbacks:\n",
            "  early_stopping:\n",
            "    monitor: val_acc\n",
            "    patience: 5\n",
            "    mode: max\n",
            "  model_checkpoint:\n",
            "    monitor: val_acc\n",
            "    mode: max\n",
            "    save_top_k: 3\n",
            "    save_last: true\n",
            "    dirpath: ./results/checkpoints\n",
            "    filename: '{epoch:02d}-{val_acc:.4f}'\n",
            "hp_search:\n",
            "  n_trials: 20\n",
            "  max_epochs_per_trial: 20\n",
            "  search_space:\n",
            "    lr:\n",
            "    - 0.001\n",
            "    - 0.1\n",
            "    momentum:\n",
            "    - 0.8\n",
            "    - 0.95\n",
            "    batch_size:\n",
            "    - 64\n",
            "    - 128\n",
            "    - 256\n",
            "\n",
            "Seed set to 42\n",
            "Downloading: \"https://github.com/facebookresearch/dino/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/dino/dino_deitsmall16_pretrain/dino_deitsmall16_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dino_deitsmall16_pretrain.pth\n",
            "100% 82.7M/82.7M [00:00<00:00, 317MB/s]\n",
            "Error executing job with overrides: ['trainer.max_epochs=5', 'experiment_name=quick_test', 'callbacks.early_stopping.patience=5']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/aml-project/src/train.py\", line 87, in train\n",
            "    if cfg.logging.use_wandb:\n",
            "       ^^^^^^^^^^^^^^^^^^^^^\n",
            "omegaconf.errors.ConfigAttributeError: Key 'use_wandb' is not in struct\n",
            "    full_key: logging.use_wandb\n",
            "    object_type=dict\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
          ]
        }
      ],
      "source": [
        "!python -m src.train \\\n",
        "    trainer.max_epochs=5 \\\n",
        "    experiment_name=quick_test \\\n",
        "    callbacks.early_stopping.patience=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23f337ee",
      "metadata": {
        "id": "23f337ee"
      },
      "outputs": [],
      "source": [
        "# !python -m src.optimize hp_search.n_trials=12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b77ec40",
      "metadata": {
        "id": "3b77ec40"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# RESULTS_DIR = f\"{PROJECT_DIR}/results\"\n",
        "\n",
        "# df = pd.read_csv(f\"{RESULTS_DIR}/optuna_results.csv\")\n",
        "# best_trial = df.loc[df['value'].idxmax()]\n",
        "\n",
        "# BEST_LR = best_trial['params_lr']\n",
        "# BEST_MOMENTUM = best_trial['params_momentum']\n",
        "# BEST_BATCH_SIZE = int(best_trial['params_batch_size'])\n",
        "\n",
        "# print(\"best hparams:\")\n",
        "# print(f\"    lr: {BEST_LR:.6f}\")\n",
        "# print(f\"    momentum: {BEST_MOMENTUM:.4f}\")\n",
        "# print(f\"    batch_size: {BEST_BATCH_SIZE}\")\n",
        "# print(f\"    val_acc: {best_trial['value']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ad03e7",
      "metadata": {
        "id": "35ad03e7"
      },
      "outputs": [],
      "source": [
        "# os.system(\n",
        "#     f\"python  -m src.train \"\n",
        "#     f\"optimizer.lr={BEST_LR} \"\n",
        "#     f\"optimizer.momentum={BEST_MOMENTUM} \"\n",
        "#     f\"data.batch_size={BEST_BATCH_SIZE} \"\n",
        "#     f\"trainer.max_epochs=100 \"\n",
        "#     f\"experiment_name=centralized_baseline\"\n",
        "# )\n",
        "\n",
        "os.system(\n",
        "    f\"python -m src.train \"\n",
        "    f\"optimizer.lr=0.01 \"\n",
        "    f\"optimizer.momentum=0.9 \"\n",
        "    f\"data.batch_size=128 \"\n",
        "    f\"trainer.max_epochs=100 \"\n",
        "    f\"experiment_name=centralized_baseline\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0507b401",
      "metadata": {
        "id": "0507b401"
      },
      "outputs": [],
      "source": [
        "# Only run if Cell 5 was interrupted\n",
        "\n",
        "# os.system(\n",
        "#     f\"python -m src.train \"\n",
        "#     f\"optimizer.lr={BEST_LR} \"\n",
        "#     f\"optimizer.momentum={BEST_MOMENTUM} \"\n",
        "#     f\"data.batch_size={BEST_BATCH_SIZE} \"\n",
        "#     f\"trainer.max_epochs=100 \"\n",
        "#     f\"experiment_name=centralized_baseline \"\n",
        "#     f\"resume_from=./results/checkpoints/last.ckpt\"\n",
        "# )\n",
        "\n",
        "os.system(\n",
        "    f\"python -m src.train \"\n",
        "    f\"optimizer.lr=0.01 \"\n",
        "    f\"optimizer.momentum=0.9 \"\n",
        "    f\"data.batch_size=128 \"\n",
        "    f\"trainer.max_epochs=100 \"\n",
        "    f\"experiment_name=centralized_baseline\"\n",
        "    f\"resume_from=./results/checkpoints/last.ckpt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abd9e788",
      "metadata": {
        "id": "abd9e788"
      },
      "outputs": [],
      "source": [
        "# AI generated plotting, I'm terrible at plotting so if someone wants to review, feel free\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "LOG_DIR = f\"{PROJECT_DIR}/results/logs\"\n",
        "RESULTS_DIR = f\"{PROJECT_DIR}/results\"\n",
        "\n",
        "experiment_name = \"centralized_baseline\"\n",
        "log_versions = sorted(os.listdir(f\"{LOG_DIR}/{experiment_name}\"))\n",
        "latest_version = log_versions[-1]\n",
        "metrics_path = f\"{LOG_DIR}/{experiment_name}/{latest_version}/metrics.csv\"\n",
        "\n",
        "print(f\"Loading: {metrics_path}\")\n",
        "metrics = pd.read_csv(metrics_path)\n",
        "\n",
        "# Separate metrics\n",
        "train_metrics = metrics[metrics['train_loss'].notna()].copy()\n",
        "val_metrics = metrics[metrics['val_loss'].notna()].copy()\n",
        "test_metrics = metrics[metrics['test_acc'].notna()].copy()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(train_metrics['epoch'], train_metrics['train_loss'], label='Train', marker='.')\n",
        "axes[0].plot(val_metrics['epoch'], val_metrics['val_loss'], label='Val', marker='.')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Loss Curves')\n",
        "axes[0].legend()\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "axes[1].plot(train_metrics['epoch'], train_metrics['train_acc'], label='Train', marker='.')\n",
        "axes[1].plot(val_metrics['epoch'], val_metrics['val_acc'], label='Val', marker='.')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].set_title('Accuracy Curves')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{RESULTS_DIR}/training_curves.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nâœ“ Results:\")\n",
        "print(f\"  Final train_acc: {train_metrics['train_acc'].iloc[-1]:.4f}\")\n",
        "print(f\"  Final val_acc:   {val_metrics['val_acc'].iloc[-1]:.4f}\")\n",
        "print(f\"  Best val_acc:    {val_metrics['val_acc'].max():.4f}\")\n",
        "if len(test_metrics) > 0:\n",
        "    print(f\"  Test acc:        {test_metrics['test_acc'].iloc[0]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c1c3a8e",
      "metadata": {
        "id": "9c1c3a8e"
      },
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "print(\"optimization history:\")\n",
        "display(IFrame(src=f\"results/optimization_history.html\", width=800, height=400))\n",
        "\n",
        "print(\"\\nparam Importances:\")\n",
        "display(IFrame(src=f\"results/param_importances.html\", width=800, height=400))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "698e797e",
      "metadata": {
        "id": "698e797e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_DIR = \"/content/drive/MyDrive/aml-project-results\"\n",
        "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "\n",
        "!cp -r {RESULTS_DIR}/* {DRIVE_DIR}/\n",
        "print(f\"Saved to {DRIVE_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e51b21b",
      "metadata": {
        "id": "2e51b21b"
      },
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"CENTRALIZED BASELINE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nBEST HYPERPARAMETERS\")\n",
        "print(\"-\" * 60)\n",
        "# print(f\"lr: {BEST_LR}\")\n",
        "# print(f\"momentum: {BEST_MOMENTUM}\")\n",
        "# print(f\"batch size: {BEST_BATCH_SIZE}\")\n",
        "\n",
        "print(\"\\nğŸ“ˆ RESULTS\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"best val_acc: {val_metrics['val_acc'].max():.4f}\")\n",
        "if len(test_metrics) > 0:\n",
        "    print(f\"test acc: {test_metrics['test_acc'].iloc[0]:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}