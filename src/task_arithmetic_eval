import torch
import copy
import os
import sys

# Ensure parent directory is in path for imports
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.model import DinoClassifier
from src.datamodule import CIFAR100DataModule

def apply_task_arithmetic(base_model, federated_model, alpha=0.5):
    """
    Implements: W_new = W_base + alpha * (W_fed - W_base)
    """
    with torch.no_grad():
        base_sd = base_model.state_dict()
        fed_sd = federated_model.state_dict()
        new_state_dict = copy.deepcopy(base_sd)
        
        for name in base_sd:
            if name in fed_sd:
                # Calculate the Task Vector (Difference in knowledge)
                task_vector = fed_sd[name].to(base_sd[name].device) - base_sd[name]
                # Scale and apply back to the original base weights
                new_state_dict[name] = base_sd[name] + alpha * task_vector
                
    base_model.load_state_dict(new_state_dict)
    return base_model

def evaluate(model, dataloader, device):
    model.to(device)
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for x, y in dataloader:
            x, y = x.to(device), y.to(device)
            logits = model(x)
            preds = torch.argmax(logits, dim=1)
            correct += (preds == y).sum().item()
            total += y.size(0)
    return correct / total

if __name__ == "__main__":
    device = torch.device("cpu") # CPU is sufficient for evaluation
    
    print("--- Starting Final Task Arithmetic Evaluation ---")
    
    # 1. Setup Data
    dm = CIFAR100DataModule(data_dir='./data', batch_size=64)
    dm.setup("test")
    test_loader = dm.test_dataloader()

    # 2. Define Paths (Updated based on your results folder)
    base_ckpt_path = "checkpoints/dino-cifar100-baseline.ckpt"
    fed_ckpt_path = "results/checkpoints/last.ckpt"

    if not os.path.exists(base_ckpt_path) or not os.path.exists(fed_ckpt_path):
        print(f"Error: Ensure {base_ckpt_path} and {fed_ckpt_path} exist.")
        sys.exit(1)

    # 3. Load Models
    print(f"Loading Baseline from: {base_ckpt_path}")
    base_model = DinoClassifier.load_from_checkpoint(base_ckpt_path)
    
    print(f"Loading Federated weights from: {fed_ckpt_path}")
    fed_model = copy.deepcopy(base_model)
    
    # Extract state_dict from the Lightning checkpoint
    checkpoint = torch.load(fed_ckpt_path, map_location=device)
    if 'state_dict' in checkpoint:
        fed_model.load_state_dict(checkpoint['state_dict'])
    else:
        fed_model.load_state_dict(checkpoint)

    # 4. Perform Alpha Sweep
    # This evaluates the Task Arithmetic effect across different magnitudes
    print(f"\n{'Scaling Factor (Alpha)':<25} | {'Test Accuracy':<15}")
    print("-" * 45)

    # Testing 0.0 (Baseline), 0.4 (Your Config), and 1.0 (Standard Aggregation)
    alphas = [0.0, 0.4, 0.7, 1.0]
    
    for alpha in alphas:
        # Create a fresh base for each iteration to avoid additive errors
        current_base = copy.deepcopy(base_model)
        
        # Apply Task Arithmetic
        arith_model = apply_task_arithmetic(current_base, fed_model, alpha=alpha)
        
        # Evaluate performance
        acc = evaluate(arith_model, test_loader, device)
        print(f"{alpha:<25} | {acc*100:>14.2f}%")

    print("\nEvaluation Complete. You can use these values for your final report.")